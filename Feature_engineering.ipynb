{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29fc730a-7dc9-4709-867a-428a5ea94455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AZN.L...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'Date' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature engineering complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 42\u001b[0m     process_all_stocks()\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed data saved in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_data/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 36\u001b[0m, in \u001b[0;36mprocess_all_stocks\u001b[1;34m(data_folder, output_folder)\u001b[0m\n\u001b[0;32m     34\u001b[0m stock_name \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_historical.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_folder, file), index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m df \u001b[38;5;241m=\u001b[39m calculate_technical_indicators(df)\n\u001b[0;32m     38\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_processed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:162\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_parse_dates_presence(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames)  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_noconvert_columns()\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:215\u001b[0m, in \u001b[0;36mCParserWrapper._set_noconvert_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    213\u001b[0m col_indices \u001b[38;5;241m=\u001b[39m [names_dict[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames]  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m noconvert_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_noconvert_dtype_columns(\n\u001b[0;32m    216\u001b[0m     col_indices,\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    218\u001b[0m )\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m noconvert_columns:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mset_noconvert(col)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:663\u001b[0m, in \u001b[0;36mParserBase._set_noconvert_dtype_columns\u001b[1;34m(self, col_indices, names)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col:\n\u001b[1;32m--> 663\u001b[0m         noconvert_columns\u001b[38;5;241m.\u001b[39madd(_set(k))\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    665\u001b[0m     noconvert_columns\u001b[38;5;241m.\u001b[39madd(_set(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col))\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:640\u001b[0m, in \u001b[0;36mParserBase._set_noconvert_dtype_columns.<locals>._set\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    637\u001b[0m     x \u001b[38;5;241m=\u001b[39m usecols[x]\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(x):\n\u001b[1;32m--> 640\u001b[0m     x \u001b[38;5;241m=\u001b[39m col_indices[names\u001b[38;5;241m.\u001b[39mindex(x)]\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mValueError\u001b[0m: 'Date' is not in list"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure the processed data directory exists\n",
    "os.makedirs(\"processed_data\", exist_ok=True)\n",
    "\n",
    "def calculate_technical_indicators(df):\n",
    "    \"\"\"Computes technical indicators for stock data.\"\"\"\n",
    "    df[\"SMA_50\"] = df[\"Close\"].rolling(window=50).mean()\n",
    "    df[\"SMA_200\"] = df[\"Close\"].rolling(window=200).mean()\n",
    "    df[\"EMA_20\"] = df[\"Close\"].ewm(span=20, adjust=False).mean()\n",
    "    df[\"EMA_50\"] = df[\"Close\"].ewm(span=50, adjust=False).mean()\n",
    "    \n",
    "    # RSI Calculation\n",
    "    delta = df[\"Close\"].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    rs = gain / loss\n",
    "    df[\"RSI_14\"] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD Calculation\n",
    "    df[\"MACD\"] = df[\"EMA_12\"] = df[\"Close\"].ewm(span=12, adjust=False).mean() - df[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df[\"Bollinger_Upper\"] = df[\"SMA_50\"] + (df[\"Close\"].rolling(20).std() * 2)\n",
    "    df[\"Bollinger_Lower\"] = df[\"SMA_50\"] - (df[\"Close\"].rolling(20).std() * 2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_all_stocks(data_folder=\"data\", output_folder=\"processed_data\"):\n",
    "    \"\"\"Loads all stock CSV files, applies feature engineering, and saves processed files.\"\"\"\n",
    "    for file in os.listdir(data_folder):\n",
    "        if file.endswith(\"_historical.csv\"):\n",
    "            stock_name = file.split(\"_historical.csv\")[0]\n",
    "            print(f\"Processing {stock_name}...\")\n",
    "            df = pd.read_csv(os.path.join(data_folder, file), index_col=\"Date\", parse_dates=True)\n",
    "            df = calculate_technical_indicators(df)\n",
    "            df.to_csv(os.path.join(output_folder, f\"{stock_name}_processed.csv\"))\n",
    "    print(\"Feature engineering complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_stocks()\n",
    "    print(\"Processed data saved in 'processed_data/' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "713f79dd-d405-47c0-938a-8cfd512d8a33",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_folder, file))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_folder' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(data_folder, file))\n",
    "print(df.head())  # Check if \"Date\" exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610ddb9e-e42b-4b1e-bf14-5ee788ea029b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Price            Close               High                Low  \\\n",
      "0      Ticker            AZN.L              AZN.L              AZN.L   \n",
      "1        Date              NaN                NaN                NaN   \n",
      "2  2020-01-02    6785.84765625  6794.706465200718  6701.688971218179   \n",
      "3  2020-01-03  6821.2822265625    6821.2822265625  6715.791470659677   \n",
      "4  2020-01-06   6753.068359375  6803.563557654467  6684.855547664141   \n",
      "\n",
      "                Open   Volume  \n",
      "0              AZN.L    AZN.L  \n",
      "1                NaN      NaN  \n",
      "2  6728.265398070333  1704325  \n",
      "3  6754.841165914164  1090818  \n",
      "4  6793.818870267201  1348181  \n"
     ]
    }
   ],
   "source": [
    "data_folder = \"data\"  # Define the correct path\n",
    "file = \"AZN.L_historical.csv\"  # Replace with an actual file from your folder\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_folder, file))\n",
    "print(df.head())  # Check if \"Date\" exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc0d98b-bcce-471a-b911-3b8feabfba24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Ticker        AZN.L      AZN.L.1      AZN.L.2      AZN.L.3    AZN.L.4\n",
      "0        Date          NaN          NaN          NaN          NaN        NaN\n",
      "1  2020-01-02  6785.847656  6794.706465  6701.688971  6728.265398  1704325.0\n",
      "2  2020-01-03  6821.282227  6821.282227  6715.791471  6754.841166  1090818.0\n",
      "3  2020-01-06  6753.068359  6803.563558  6684.855548  6793.818870  1348181.0\n",
      "4  2020-01-07  6772.558594  6790.276209  6699.916369  6739.781005  1308820.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(data_folder, file), skiprows=1)\n",
    "print(df.head())  # Check if \"Date\" is correctly parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa658ac-3246-42ef-acec-3ca5707e5f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikah\\AppData\\Local\\Temp\\ipykernel_53364\\970323001.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n"
     ]
    },
    {
     "ename": "DateParseError",
     "evalue": "Unknown datetime string format, unable to parse: Date, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Convert 'Date' to datetime format\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Set 'Date' as index\u001b[39;00m\n\u001b[0;32m     13\u001b[0m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1112\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1111\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m         values \u001b[38;5;241m=\u001b[39m convert_listlike(arg\u001b[38;5;241m.\u001b[39m_values, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1113\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:490\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m--> 490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    491\u001b[0m     arg,\n\u001b[0;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m    493\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[0;32m    494\u001b[0m     utc\u001b[38;5;241m=\u001b[39mutc,\n\u001b[0;32m    495\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m )\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    502\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2346\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object)\u001b[0m\n\u001b[0;32m   2343\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[0;32m   2344\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[1;32m-> 2346\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m tslib\u001b[38;5;241m.\u001b[39marray_to_datetime(\n\u001b[0;32m   2347\u001b[0m     data,\n\u001b[0;32m   2348\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   2349\u001b[0m     utc\u001b[38;5;241m=\u001b[39mutc,\n\u001b[0;32m   2350\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   2351\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[0;32m   2352\u001b[0m )\n\u001b[0;32m   2354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2355\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2356\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2357\u001b[0m     \u001b[38;5;66;03m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[0;32m   2358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m), tz_parsed\n",
      "File \u001b[1;32mtslib.pyx:403\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:552\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:517\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mconversion.pyx:546\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:331\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:660\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse: Date, at position 0"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(data_folder, file), skiprows=1)  # Skip incorrect header row\n",
    "\n",
    "# Rename columns manually\n",
    "df.columns = [\"Date\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "\n",
    "# Drop NaN rows\n",
    "df = df.dropna(subset=[\"Date\"])\n",
    "\n",
    "# Convert 'Date' to datetime format\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "# Set 'Date' as index\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "print(df.head())  # Check if everything is correctly formatted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f9d0be4-d6c3-4fa0-b514-c3d8a52d92ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Close         High          Low         Open     Volume\n",
      "Date                                                                     \n",
      "2020-01-02  6785.847656  6794.706465  6701.688971  6728.265398  1704325.0\n",
      "2020-01-03  6821.282227  6821.282227  6715.791471  6754.841166  1090818.0\n",
      "2020-01-06  6753.068359  6803.563558  6684.855548  6793.818870  1348181.0\n",
      "2020-01-07  6772.558594  6790.276209  6699.916369  6739.781005  1308820.0\n",
      "2020-01-08  6755.727539  6793.820417  6714.091138  6747.754611  1256533.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(data_folder, file), skiprows=1)\n",
    "\n",
    "# Rename columns properly\n",
    "df.columns = [\"Date\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "\n",
    "# Drop any NaN rows in the Date column\n",
    "df = df.dropna(subset=[\"Date\"])\n",
    "\n",
    "# Ensure the Date column is in string format before parsing\n",
    "df[\"Date\"] = df[\"Date\"].astype(str)\n",
    "\n",
    "# Explicitly define the date format\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\", errors=\"coerce\")  # Adjust format if needed\n",
    "\n",
    "# Drop rows where Date couldn't be parsed\n",
    "df = df.dropna(subset=[\"Date\"])\n",
    "\n",
    "# Set Date as the index\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "print(df.head())  # Check output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c25895a-5c26-4ebd-9aec-7123f916f0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AZN.L from data\\AZN.L_historical.csv...\n",
      "Processed AZN.L successfully!\n",
      "Processing BATS.L from data\\BATS.L_historical.csv...\n",
      "Processed BATS.L successfully!\n",
      "Processing BP.L from data\\BP.L_historical.csv...\n",
      "Processed BP.L successfully!\n",
      "Processing GSK.L from data\\GSK.L_historical.csv...\n",
      "Processed GSK.L successfully!\n",
      "Processing HSBA.L from data\\HSBA.L_historical.csv...\n",
      "Processed HSBA.L successfully!\n",
      "Processing LSEG.L from data\\LSEG.L_historical.csv...\n",
      "Processed LSEG.L successfully!\n",
      "Processing REL.L from data\\REL.L_historical.csv...\n",
      "Processed REL.L successfully!\n",
      "Processing RIO.L from data\\RIO.L_historical.csv...\n",
      "Processed RIO.L successfully!\n",
      "Processing SHEL.L from data\\SHEL.L_historical.csv...\n",
      "Processed SHEL.L successfully!\n",
      "Processing ULVR.L from data\\ULVR.L_historical.csv...\n",
      "Processed ULVR.L successfully!\n",
      "Feature engineering complete.\n",
      "Processed data saved in 'processed_data/' directory.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ensure the processed data directory exists\n",
    "os.makedirs(\"processed_data\", exist_ok=True)\n",
    "\n",
    "def calculate_technical_indicators(df):\n",
    "    \"\"\"Computes technical indicators for stock data.\"\"\"\n",
    "    df[\"SMA_50\"] = df[\"Close\"].rolling(window=50).mean()\n",
    "    df[\"SMA_200\"] = df[\"Close\"].rolling(window=200).mean()\n",
    "    df[\"EMA_20\"] = df[\"Close\"].ewm(span=20, adjust=False).mean()\n",
    "    df[\"EMA_50\"] = df[\"Close\"].ewm(span=50, adjust=False).mean()\n",
    "    \n",
    "    # RSI Calculation\n",
    "    delta = df[\"Close\"].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    rs = gain / loss\n",
    "    df[\"RSI_14\"] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD Calculation\n",
    "    df[\"EMA_12\"] = df[\"Close\"].ewm(span=12, adjust=False).mean()\n",
    "    df[\"EMA_26\"] = df[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "    df[\"MACD\"] = df[\"EMA_12\"] - df[\"EMA_26\"]\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df[\"Bollinger_Upper\"] = df[\"SMA_50\"] + (df[\"Close\"].rolling(20).std() * 2)\n",
    "    df[\"Bollinger_Lower\"] = df[\"SMA_50\"] - (df[\"Close\"].rolling(20).std() * 2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_all_stocks(data_folder=\"data\", output_folder=\"processed_data\"):\n",
    "    \"\"\"Loads all stock CSV files, applies feature engineering, and saves processed files.\"\"\"\n",
    "    for file in os.listdir(data_folder):\n",
    "        if file.endswith(\"_historical.csv\"):\n",
    "            stock_name = file.split(\"_historical.csv\")[0]\n",
    "            file_path = os.path.join(data_folder, file)\n",
    "            print(f\"Processing {stock_name} from {file_path}...\")\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_csv(file_path, skiprows=1)\n",
    "                df.columns = [\"Date\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "                df = df.dropna(subset=[\"Date\"])\n",
    "                df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "                df = df.dropna(subset=[\"Date\"])\n",
    "                df.set_index(\"Date\", inplace=True)\n",
    "                \n",
    "                df = calculate_technical_indicators(df)\n",
    "                \n",
    "                output_path = os.path.join(output_folder, f\"{stock_name}_processed.csv\")\n",
    "                df.to_csv(output_path)\n",
    "                print(f\"Processed {stock_name} successfully!\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "    print(\"Feature engineering complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_stocks()\n",
    "    print(\"Processed data saved in 'processed_data/' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ca95b-bf76-4ba6-9e73-a661f1b1a449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
